{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYyMk_z1WenK",
        "outputId": "7231b120-bcf4-467a-d680-02e7f29dc78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "NLTK: 3.8.1\n",
            "Scikit-learn: 1.2.2\n",
            "Pandas: 1.5.3\n",
            "Numpy: 1.23.5\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import nltk\n",
        "import sklearn\n",
        "import pandas\n",
        "import numpy\n",
        "\n",
        "print('Python: {}'.format(sys.version))\n",
        "print('NLTK: {}'.format(nltk.__version__))\n",
        "print('Scikit-learn: {}'.format(sklearn.__version__))\n",
        "print('Pandas: {}'.format(pandas.__version__))\n",
        "print('Numpy: {}'.format(numpy.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d uciml/sms-spam-collection-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMG1574bWu08",
        "outputId": "fc13769c-b4ae-4374-f048-eafae3d2e944"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading sms-spam-collection-dataset.zip to /content\n",
            "  0% 0.00/211k [00:00<?, ?B/s]\n",
            "100% 211k/211k [00:00<00:00, 65.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/sms-spam-collection-dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5pJcp_SXj-_",
        "outputId": "82c904d3-c320-4e41-e90c-7aae186f1c4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sms-spam-collection-dataset.zip\n",
            "  inflating: spam.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_table('/content/SMSSpamCollection', header=None, encoding='utf-8')"
      ],
      "metadata": {
        "id": "jNFsGZ-QYCab"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print useful information about the dataset\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSbmqxUZYazH",
        "outputId": "70c96427-65ef-4b47-f355-514bff398151"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       5572 non-null   object\n",
            " 1   1       5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n",
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distrinution\n",
        "classes = df[0]\n",
        "print(classes.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q8lRr8WZIso",
        "outputId": "7f50f6ef-d08d-4aae-a775-ce70ddb91a4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham     4825\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# convert class labels to binary values, 0 = ham and 1 = spam\n",
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(classes)\n",
        "\n",
        "print(Y[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFKQ4ApeZQIr",
        "outputId": "ab7cd121-6f4c-49d3-adb4-04f14be3fd63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 1 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_messages = df[1]\n",
        "print(text_messages[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNTIDpJsZivv",
        "outputId": "f75b1cab-64b6-4e78-f385-76150b192592"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Go until jurong point, crazy.. Available only ...\n",
            "1                        Ok lar... Joking wif u oni...\n",
            "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    U dun say so early hor... U c already then say...\n",
            "4    Nah I don't think he goes to usf, he lives aro...\n",
            "5    FreeMsg Hey there darling it's been 3 week's n...\n",
            "6    Even my brother is not like to speak with me. ...\n",
            "7    As per your request 'Melle Melle (Oru Minnamin...\n",
            "8    WINNER!! As a valued network customer you have...\n",
            "9    Had your mobile 11 months or more? U R entitle...\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular Expressions"
      ],
      "metadata": {
        "id": "7K_17tGVcfJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
        "\n",
        "# Replace email addresses with 'email'\n",
        "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2.}$',\n",
        "                                      'emailaddress')\n",
        "\n",
        "# Replace URLs with webaddress\n",
        "processed = text_messages.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                      'webaddress')\n",
        "\n",
        "# Replace money symbols with 'moneysymb'\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
        "\n",
        "# Replace 10 digit phone numbers\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                  'phonenumbr')\n",
        "# Replace numbers with 'numbr'\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot61D58rcdIF",
        "outputId": "93a5721c-84b8-4ee2-9c03-55ba9fabe5e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-73ec7b8c8abc>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2.}$',\n",
            "<ipython-input-15-73ec7b8c8abc>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = text_messages.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
            "<ipython-input-15-73ec7b8c8abc>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
            "<ipython-input-15-73ec7b8c8abc>:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
            "<ipython-input-15-73ec7b8c8abc>:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "# Replace whitespace between terms with a single space\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# Remove leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCZH4BPddjyV",
        "outputId": "9c6e130f-4be7-4d11-e3e3-c54566aa88c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-7c4c3441a6d5>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
            "<ipython-input-16-7c4c3441a6d5>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = processed.str.replace(r'\\s+', ' ')\n",
            "<ipython-input-16-7c4c3441a6d5>:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change words to lower case -Hello, HELLO, hello are all the same word\n",
        "\n",
        "processed = processed.str.lower()\n",
        "print(processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKsCNvMAd_Rv",
        "outputId": "a7e723e5-c221-4f12-ad05-0d87ac162adc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       go until jurong point crazy available only in ...\n",
            "1                                 ok lar joking wif u oni\n",
            "2       free entry in numbr a wkly comp to win fa cup ...\n",
            "3             u dun say so early hor u c already then say\n",
            "4       nah i don t think he goes to usf he lives arou...\n",
            "                              ...                        \n",
            "5567    this is the numbrnd time we have tried numbr c...\n",
            "5568                  will ü b going to esplanade fr home\n",
            "5569    pity was in mood for that so any other suggest...\n",
            "5570    the guy did some bitching but i acted like i d...\n",
            "5571                            rofl its true to its name\n",
            "Name: 1, Length: 5572, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove word stems using a Porter stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    ps.stem(term) for term in x.split()))"
      ],
      "metadata": {
        "id": "s18EmWP2eLJJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Features"
      ],
      "metadata": {
        "id": "DHLLM2LXeoe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# create bag-of-words\n",
        "all_words = []\n",
        "\n",
        "for message in processed:\n",
        "    words = word_tokenize(message)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCZcECChekDf",
        "outputId": "4c00f9a5-7b27-4377-8d02-4f194efad736"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the total number of words and the 15 most common words\n",
        "\n",
        "print('Number of words: {}'.format(len(all_words)))\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJmzpWoTe8r8",
        "outputId": "fd1873fc-4788-4188-9962-2b77b22090aa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words: 6690\n",
            "Most common words: [('i', 3021), ('numbr', 2648), ('to', 2253), ('you', 2245), ('a', 1448), ('the', 1339), ('u', 1207), ('it', 980), ('and', 980), ('in', 903), ('is', 897), ('me', 807), ('my', 767), ('for', 710), ('your', 706)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use th 1500 most common words aa features\n",
        "word_features = list(all_words.keys())[:1500]"
      ],
      "metadata": {
        "id": "jjJbtjhqfdrN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_features(message):\n",
        "  word = word_tokenize(message)\n",
        "  features = {}\n",
        "  for word in word_features:\n",
        "    features[word] = (word in words)\n",
        "\n",
        "  return features\n",
        "\n",
        "# Example\n",
        "features = find_features(processed[0])\n",
        "for key, value in features.items():\n",
        "  if value== True:\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZU_cxNsfoj5",
        "outputId": "6dda21aa-8629-48c0-b575-42fc48c3273e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to\n",
            "it\n",
            "name\n",
            "true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets do it for all the messages\n",
        "messages = zip(processed, Y)\n",
        "\n",
        "# define a seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed = seed\n",
        "np.random.shuffle(messages)\n",
        "\n",
        "# call find_features function for each SMS message\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "NsTaL9_tgE4o",
        "outputId": "2e5a879b-7950-4d7b-d62d-64fb50c6deed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'zip' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f569ffa56fb0>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# call find_features function for each SMS message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.shuffle\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'zip' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "#split the data into training and testing dataset\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state= seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "pDtdi1Umg5nN",
        "outputId": "67a861eb-914c-4044-af82-db0d28fb8939"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'featuresets' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d566ec47f35e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#split the data into training and testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'featuresets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "metadata": {
        "id": "gT6OAPfxhnnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
        "\n",
        "#train the model on the training data\n",
        "modle.train(training)\n",
        "\n",
        "# and test on the testset\n",
        "accuracy =  nltk.classify.accuracy(model, testing)*100\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "id": "K3qWn6jthtf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "#Define models to train\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifier = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter =100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = zip(names, classifiers)\n",
        "\n",
        "for name, model in models:\n",
        "  nltk_model = SklearnClassifier(model)\n",
        "  nltk_model.train(training)\n",
        "  accuracy = nltk.classify.accuracy(nltk_model,testing)*100\n",
        "  print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "metadata": {
        "id": "SfFBGh01iPga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "models = zip(names, classifiers)\n",
        "\n",
        "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs =-1))\n",
        "nltk_ensemble.train(training)\n",
        "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "_JmiETdCkwnI",
        "outputId": "222ffd2b-362d-44d4-e7f3-02e3c224ed2d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'KNeighborsClassifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d93942d606ff>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m          \"Naive Bayes\", \"SVM Linear\"]\n\u001b[1;32m      5\u001b[0m classifiers = [\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make class label predicion for testing set\n",
        "txt_features, labels = zip(*testing)\n",
        "\n",
        "prediction = nltk_ensemble.classify_many(txt_features)"
      ],
      "metadata": {
        "id": "phYfTbbllWou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print a confusion matrix and a classification report\n",
        "print(classification_report(labels, prediction))\n",
        "\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(labels, prediction),\n",
        "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
        "    columns = [['predicted', 'predicted'], ['ham', 'spam']]\n",
        ")"
      ],
      "metadata": {
        "id": "_U74E-CYlzQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}